INTRODUCTION 
RECURRENT / CONVOLUTIONAL NEURAL NETWORKS
SELF ATTENTION
MULTI HEAD SELF ATTENTION
PARAMETERS
TOKENIZER
POSTIONAL ENCODING
FEED FORWARD
TRANSFORMERS
TYPES 
ENCODERS DECODERS
INCONTEXT LEARNING EXAMPLES
ONE SHOT ZERO SHOT INFERENCE FEW SHOT LARGER VS SMALLER MODELS
CONTEXT WINDOW
CONFIGURATION
INFERENCE PARAMETERS
MAX NEW TOKENS
STOP TOKEN
GREEDY DECODING / RANDOM SAMPLING 
PROBABILITY DISTRIBUTION
TOP K AND TOP P 
TEMPERATURE - RANDOMNESS
< 1 COOL \\  > 1 WARM 
SCOPE
SCRATCH OR PRETRAINED
FINE TUNING
PROMPT ENGINEERING
REINFORCEMENT LEARNING
EVALUATION
OPTIMIZA AND DEPLOY
